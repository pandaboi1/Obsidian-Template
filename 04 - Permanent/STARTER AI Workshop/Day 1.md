---
date: 2024-05-29T09:23:00
tags:
  - tech
  - AI
  - Indie
cssclasses:
  - daily
---
# Day 1 

#### Presenters : 
- Soumya D. Mohanty
- [Dr. Lakshman Tamil](<#Building AI Equality and Fairness>)
- [Gopal Gupta](<#Interpretability, Understandability, and Trustworthiness in AI>)
- Dept. of Physics and Astronomy
- Additional Support - NIH, NVIDIA, DLI, Physics and Astronomy
- UTRGV Grad. Poster Presentations

#### S.T.A.R.T.E.R
South Texas AI Training and Education Resources ( [starter.utrgv.edu](https://starter.utrgv.edu/workshops) )

#### CRADLE
- GPU cluster
- 2 (out of 14) nodes ==dedicated to STARTER==
- Scalability depending on necessity 

---
# Workshop pt1 @9:30am
## Building AI Equality and Fairness
### Dr. Lakshman Tamil - MedCognetics

Founded [MedCognetics](https://www.medcognetics.com) an unbiased AI company for healthcare. [link to section](#MedCognetics)
#### AI Evolution (past to future)
- ANI.
	- Virtual assistant
	- Image recognition
	- Recommendation Algorithm
	- Autonomous Vehicle
- AGI (We are here)
	- Positive development
	- Significant social benefits
- Super Intelligent AI ASI
	- Transformative but unpredictable 
	- Solve complex problems
	- May pose existential threat
- Sentient AI
	- Philosophical currently
	- Pose ethical & existential threat

#### Artificial Intelligence (A.I.)
Made up from **two** parts [[#Machine Learning]] and [[#Machine Reasoning]].  Understanding why both are important you can build a parameters to prevent disasters in any groups. 

Humans can understand reason and learn, and they recommend to read [“Thinking, Fast and Slow” by Daniel Kahneman](https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555) gain insight on *why* we think like this. 

#### Machine Learning
Given background knowledge, positive and negative examples of a concept (training data), goal of machine learning is to learn the general rule or function that captures that concept. 

##### Neural Networks
- Information is processed in **neurons**
- Signals are passed between neurons via connection links
- Each connection link has an associated weight, which multiplies the signal being transferred.
- The weight decided the output of the neural network 
- Each neuron applies an activation function to its net input  (sum of individual inputs) to get its output

##### Training (Backpropagation)
- The process of finding appropriate weights it called *training*
- 

##### Applications of Neural Networks
- 
#### Machine Reasoning
Given pieces of information (axioms) deduce new knowledge

#### MedCognetics 
##### Their Research
- Has built their model for diversity
- Specialization on Breast Cancer 

[NewsDirect article BY MEDCOGNETICS](https://newsdirect.com/news/medcognetics-secures-groundbreaking-patent-for-inclusive-unbiased-medical-imaging-ai-technology-in-mammography-844844123)
In a significant stride towards equitable healthcare technology, [MedCognetics, Inc](https://u.newsdirect.com/Em4-uMp5rmfktjibF74rFA9llJQUWOnrl5eX6-WmpiTnp-ellmQmF-sl5-fqM-SllhdnlCYBAgAA__8TDc37jTeNCEPNy1BT7PPFCycaoCXS-Wkzx5M1w)., a company focusing on [medical imaging AI](https://u.newsdirect.com/Em4-uMp5rmfktjibF74rFA9llJQUFFvp6xcUlCYV65UWF5Tk66Xnl-mnZBYVpyYWJWfoFpQm5WQm6xcUZeaV6Kfkl-fl5CemBKSk6RsaWppYGFmaM-SllhdnlCYBAgAA__8_JGbT-JyUQhLB3KHcYGJNHHdrT4sXwpt04utag), today announced it has been awarded patent number 11,948,297 by the United States Patent and Trademark Office (USPTO).

The patent covers architectural strategies and methodologies for achieving unbiased AI in breast imaging. This innovation is backed by MedCognetics’ peer-reviewed publications in industry conferences such as the Radiological Society North America (RSNA) 2023, the European Society of Radiology (ESR) 2024, and a grant from the National Institutes of Health (NIH). This breakthrough is set to redefine the development of AI in the medical field ensuring MedCognetics’ algorithms maintain high performance across different patient demographics, thereby guaranteeing consistent, fair, superior patient outcomes.

"This patent is a reflection of our team's focused pursuit of innovation and commitment to inclusivity,” said Ron Nag, CEO of MedCognetics, Inc. “Our technology is not just about improving patient outcomes through earlier and more accurate diagnoses; the focus is on fostering equality in technological development and ensuring universal access to advancements in healthcare systems worldwide. We remain dedicated to progressing in the field of unbiased medical imaging technology.”

MedCognetics is actively engaged in partnerships with leading healthcare institutions and research organizations to bring its patented AI technology into clinical practice, aiming for widespread patient benefit from these advancements at the earliest.

Full details of the allowance are listed in the Issue Notification Certificate issued by the USPTO. For further information about MedCognetics and its pioneering medical imaging AI technology, please visit www.medcognetics.com.

**About MedCognetics, Inc.**

MedCognetics provides an advanced AI software platform that integrates into radiology workflow. In addition, the AI algorithm is trained on a diverse global patient dataset to mitigate data biasing. The future of AI in healthcare is unbiased services and MedCognetics is at the forefront of creating a more predictable medical outcome and ultimately saving lives. Founded in 2020, the company is based in Dallas, Texas. For more information, please visit our website at [www.medcognetics.com](https://u.newsdirect.com/Em4-uMp5rmfktjibF74rFA9llJQUWOnrl5eX6-WmpiTnp-ellmQmF-sl5-cy5KWWF2eUJgECAAD__w99CGajOm6-pDbdmzCd3D-nXyClDdu4E1BZr6Fg).


## Interpretability, Understandability, and Trustworthiness in AI
### Gopal Gupta - U.T.D. Grad. Professor

#### Machine Learning Model: AI is a Black Box
##### Trustworthiness (IBM.com)
- That it is fair, reliable, can be held accountable for, and can cause NO harm.
- That it can not be tempered with and be secure
- Be able to look inside the model to understand how it works
##### Understandability
- Model need to able to be corrected manually
- Follow the law in countries
- Develops trust in the model

#### How do Humans Interpret Information?
Sensory context, inferencing, and prior knowledge of the given information to make a conclusion to what the given information.

#### Understandable AI as Default Rules
**FOLD** - learn default rules that capture patterns in data
**Default Logic** - can express 

## Lunch from 12pm - 1:30pm

---
# Workshop pt2 @1:30pm

## Intro to AI & Interdisciplinary Research
### Dr. Kim - U.T.R.G.V. Grad. Professor

#### Perception 
How to distinguish differences in images and identify conclusions. 

#### Learning 
#####  Train and Test Data
Given **training data** is roughly 80% overall data and **testing data** is the other 20%.

##### Machine Learning vs. Deep Learning 
**Machine learning** has human *intervention layer* to interpret data, while **deep learning** is just the normal layer. 

3 layer are:
- Input
- Neural Network
- Output

#### To Build an AI
##### 1. Fundamental Principles for Collaboration
###### Build Team
- 
##### 2. Mutual  Presentation
###### Both parties should present their research
- Crucial to

##### 3. Data Preparation and Methods
###### Data Structure
Data stored in a database, Excel spreadsheet, etc. , which 

###### Time Series Date

##### 4. Model Implementation
Using TensorFlow or **PyTorch**

TensorFlow is widely used, but PyTorch is becoming the new standard
##### 5. Training, Evaluation, and Analysis
###### Training and Evaluation

#### Reinforcement Learning 
##### Algorithms
--- 


## AI-Driven Design and Synthesis of Nanomaterials for the detection of fentanyl and derivatives
### Amber Garcia and Dr. Julie P. Vanegas - U.T.R.G.V. Research Group

#### Abstract
The opioid crisis, significantly intensified by the widespread abuse of synthetic opioids like fentanyl, represents a formidable public health challenge. Conventional opioid detection methodologies lack the sensitivity and specificity required to effectively counter the rapid emergence and proliferation of these potent synthetic substances. This project proposes the novel development of aptamer-based nanosensors, employing cutting-edge advancements in nanotechnology, biochemistry, and artificial intelligence (AI) to overcome this inadequacy.


## Autoencoders in Reinforcement Learning
### Hector Lugo, Arturo Meza-Canales, Osvaldo Garza, Dr. Erik Enriquez, and Dr. Dong-Chul Kim

#### Abstract
This project aims to enhance the efficiency of machine learning algorithms, with a particular focus on reinforcement learning (RL) models. Our objective is to reduce the complexity of environmental observations in order to increase the overall efficiency and effectiveness of RL agents. To achieve this, we will integrate an autoencoder, a neural network designed to compress data while preserving its key features. Our research will employ several benchmark models from MuJoCo, allowing us to compare the model’s performance when trained with encoded versus raw observational data. Through this investigation, we anticipate uncovering insights that could lead to more streamlined training, and create avenues to train RL agents on more complex tasks.



## Control Strategies for Cooperative Multi-Robot Tasks Using Multi-Agent Reinforcement Learning
### Daniel Masamba, Tyler Morgan, Dr. Erik Enriquez, and Dr. Dong-Chul Kim
#### Abstract
This research project used a curriculum learning approach to train simulated agents with Reinforcement Learning (RL) techniques. By training agents on tasks simpler than the one meant for them to achieve, we saw more efficient and effective training for desired tasks than agents with no previous training. This could also lead to multiple, previously trained agents being able to collaborate on tasks more effectively. The research project’s priorities shifted from exploring the applications of Multi-Agent Reinforcement Learning (MARL) as we explored in more depth the variations of most effectively training a single agent as a precursor. However, our methods could lead to a more meaningful exploration of MARL strategies in the future.


## The Development of a Disability Assessment Tool using Biosensors and Machine Learning for Persons with Multiple Sclerosis
### Jofred Gonzalez, Dr. Damian Valles, and Dr. John W. Farrell III CSCS, CPSS
#### Abstract
The development of a tool to assess Multiple Sclerosis severity using Inertial Mass Units (Motion Sensors) and Machine Learning aims to simplify the assessment of MS severity for the lower extremities of the human body. More specifically, this presentation discusses how data was collected and prepared to be processed by a non-binary classification machine learning algorithm to create a model that will output a number from 0 to 10 emulating the Expanded Disability Status Scale assessment.


## AI based prediction of the charge storage capability of Lithium-ion battery materials
### Manoj Chhetri and Dr. Karen Martirosyan
#### Abstract
In this report, a machine learning approach was implemented to a dataset of 2345 entries of rechargeable Li-ion battery materials, obtained from MaterialsProject online portal, to predict the gravimetric charge storing capacity (mAh/g) which is a crucial parameter in a battery for its energy storage capabilities. This study highlighted the possibility of using machine learning models in materials science by integrating domain-specific knowledge with advance statistical techniques. It provides insight for informed decision-making and tuning the important parameters to achieve the highest possible charge storage capacity in battery materials design and optimization process. By accurately predicting the gravimetric capacity of battery materials taking into account of intrinsic battery properties such as voltage, energy density and stability, our model contributes to discover and deploy more efficient and sustainable battery solutions. 
	

## IntelliBeeHive: An Automated Honey Bee, Pollen, and Varroa Destructor Monitoring System
### Christian I. Narcia-Macias, Joselito Guardado, Jocell Rodriguez, Dr. Joanne Rampersad-Ammons, Dr. Erik Enriquez, and Dr. Dong-Chul Kim
####  Abstract
Utilizing computer vision and the latest technological advancements, in this study, we developed a honey bee monitoring system that aims to enhance our understanding of Colony Collapse Disorder, honey bee behavior, population decline, and overall hive health. The system is positioned at the hive entrance providing real-time data, enabling beekeepers to closely monitor the hive's activity and health through an account-based website. Using machine learning, our monitoring system can accurately track honey bees, monitor pollen-gathering activity, and detect Varroa mites, all without causing any disruption to the honey bees. Moreover, we have ensured that the development of this monitoring system utilizes cost-effective technology, making it accessible to apiaries of various scales, including hobbyists, commercial beekeeping businesses, and researchers. The inference models used to detect honey bees, pollen, and mites are based on the YOLOv7-tiny architecture trained with our own data. The F1-score for honey bee model recognition is 0.95 and the precision and recall value is 0.981. For our pollen and mite object detection model F1-score is 0.95 and the precision and recall value is 0.821 for pollen and 0.996 for "mite". The overall performance of our IntelliBeeHive system demonstrates its effectiveness in monitoring the honey bee's activity, achieving an accuracy of 96.28 % in tracking and our pollen model achieved a F1-score of 0.831.


